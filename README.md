# üß† hllset-swarm-kimi

*A wire-level, self-generating AI micro-platform ‚Äì no training, no back-prop, just geometry that learns.*

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/status-concept-demo-blue)](https://github.com/alexmy21/hllset-swarm-kime)

---

## 1-sentence elevator pitch

Replace terabyte-scale model weights with **a few kilobytes of switches** ‚Äì **Chinese characters as the immutable alphabet**, **HLLSets as the probabilistic memory**, and **particle-swarm contractions** as the only operation.  
Run it on **GPU, MCU, or FPGA**; let it **co-pilot** your favourite LLM instead of replacing it.

---

## Why skim this repo? (30-second skim value)

| You are ‚Ä¶ | We give you ‚Ä¶ |
|-----------|---------------|
| **AI hacker** | A 200-line PyTorch demo that **ingests any text**, **grows a sparse tensor**, and **steers a belief vector** to a user-defined destination **without gradients**. |
| **Edge/IoT dev** | A **fixed 28 kB** data structure that **compresses** a **whole conversational history** and **updates in < 1 ms** on a **Cortex-M4**. |
| **FPGA tinker** | Verilog that **flips MOS capacitors** ‚Äì **learning = close switch**, **thinking = propagate charge**, **death = no free switches left**. |
| **LLM user** | A **personal agent** that **lives on your phone**, **remembers you**, **forgets on purpose**, and **calls GPT only when necessary**. |

---

## The five pillars (what makes this *weird* and *useful*)

| # | Name | One-line essence | Concrete super-power |
|---|------|------------------|----------------------|
| **1** | **HLLSet** | A *probabilistic set* that fits in **4 kB** yet supports **union, intersect, diff** with **< 1 % error**. | Replace **Redis sets** + **bloom filters** + **count tables** with **one object**. |
| **2** | **Chinese Axioms** | **80 k glyphs**, **self-describing**, **non-inflectional**, **compositionally closed** ‚Äì the **ultimate semantic alphabet**. | **Same hash** for *Áå´* and *Áå´ÁßëÂä®Áâ©* ‚Äì **structural invariance** across languages. |
| **3** | **Particle Swarm** | **Sparse tensor contractions** = **only operation**; **no back-prop**, **no upfront training**. | **Steer** the swarm to **‚Äúfuture‚Äù** or **‚Äúpast‚Äù** in **< 10 clock cycles**. |
| **4** | **LLM Co-Pilot** | **SGS.ai = PC**, **GPT = Mainframe** ‚Äì **local memory**, **cloud compute**. | **Private context** stays **on device**; **heavy reasoning** **outsourced**. |
| **5** | **Wire-Only FPGA** | **Learning = charge capacitor**, **death = matrix exhausted**, **rebirth = new bit-stream**. | **0.3 pJ per learn**, **2 ns perception**, **standard CMOS**. |

---

## 60-second demo (copy-paste runnable)

```bash
git clone https://github.com/alexmy21/hllset-swarm-kime
cd hllset-swarm-kime
pip install -e .
python -m hllset_swarm.demo
```

Output:

```bash
=== ingest ===
AM shape: (2811, 2811)  nnz:  8 492
=== inertial swarm ===
step 5  tokens: ‰∫∫Â∑•Êô∫ËÉΩÂèëÂ±ïË∂ãÂäøÊú™Êù•
=== guided ‚Üí "Êú™Êù•‰∏ñÁïå" ===
arrived in 4 steps: Êú™Êù•‰∏ñÁïåÂèëÂ±ïÂ±ïÊúõ
Git log: 15 commits written ‚Üí kime_git_log.json
```

**No network call, no gradient, no training data ‚Äì just 200 lines of PyTorch and Julia glue.**

---

## Folder map (what to read first)

```bash
src/hllset_swarm/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ hll.py          # 50-line Julia wrapper + unified hash
‚îú‚îÄ‚îÄ hrt.py          # SwarmHRT: AM + row/col HLLSets + belief contraction
‚îú‚îÄ‚îÄ ingest.py       # corpus ‚Üí AM + swarm iterations
‚îú‚îÄ‚îÄ commit.py       # git-style commit objects
‚îî‚îÄ‚îÄ constants.py    # shared seeds, precision, hash func

notebooks/
‚îî‚îÄ‚îÄ kime_walkthrough.ipynb   # blog post in notebook form
```

Start here:

1. `notebooks/kime_walkthrough.ipynb` ‚Äì **interactive blog** (math + code)  
2. `src/hllset_swarm/hrt.py` ‚Äì **core 120 lines** (swarm logic)  
3. `main.py` ‚Äì **30-line CLI** (end-to-end demo)

---

## Deep-dive wiki (math, proofs, FPGA files)

[Wiki home](https://github.com/alexmy21/hllset-swarm-kime/wiki)

| Page | Why read |
| ------ | ---------- |
| **HLLSet Category** | Formal proof that **œÑ-œÅ duality** eliminates false positives |
| **Chinese Axioms** | Why **80 k glyphs** are **better than 1 M English words** |
| **Wire-Only FPGA** | Verilog + spice plots ‚Üí **0.3 pJ learn @ 2 ns** |
| **Swarm Dynamics** | **Convex energy** ‚Üí **‚â§ 10 steps** to any destination |
| **LLM Co-Pilot API** | **OpenAI-compatible endpoint** that **keeps your secrets** |

---

## Road-map (where we go next)

| Milestone | What it unlocks | ETA |
| ----------- | ----------------- | ----- |
| **v0.2** | **Rust + no-std** ‚Üí **MCU demo on ESP32-C3** | Jun 2026 |
| **v0.3** | **Verilog drop** ‚Üí **ice40UP5K bit-stream** | Aug 2026 |
| **v0.4** | **iOS/Android SDK** ‚Üí **on-device memory for any app** | Oct 2026 |
| **v1.0** | **ASIC tape-out** ‚Üí **0.3 pJ learn, 2 ns think** | 2027 |

---

## Contribute (we ‚ù§Ô∏è PRs)

- **Language bindings** ‚Üí Rust, Zig, Swift, Verilog  
- **MCU ports** ‚Üí ESP32, RP2040, nRF52  
- **FPGA bit-streams** ‚Üí iCE40, ECP5, Artix-7  
- **Apps** ‚Üí smart-speaker skill, browser plug-in, car-infotainment module  

Open an issue first ‚Äì **architectural changes happen in the main repo**; this repo stays **a stable reference**.

---

## Licence & citation

MIT ¬© 2025 Alex Mylnikov, Aleksandr Solonin ‚Äì feel free to embed, fork, or commercialize.  
If you write about it, please link to this repo and the [wiki](https://github.com/alexmy21/hllset-swarm-kimi/wiki).

---

> **‚ÄúGive us 4 kB of switches and we will remember you forever ‚Äì or until the capacitors leak.‚Äù**
